{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python notebook for Make Your Own Neural Network\n",
    "# code for a 3-layer neural network, and code for learning the MNIST dataset\n",
    "# this version asks the network what the image should be, given a label\n",
    "# (c) Tariq Rashid, 2016\n",
    "# license is GPLv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit(), and its inverse logit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    \n",
    "    # backquery the neural network\n",
    "    # we'll use the same termnimology to each item, \n",
    "    # eg target are the values at the right of the network, albeit used as input\n",
    "    # eg hidden_output is the signal to the right of the middle nodes\n",
    "    def backquery(self, targets_list):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hideen layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_dataset/mnist_train_100.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    print e\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"mnist_dataset/mnist_test_10.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorecard_array = numpy.asarray(scorecard)\n",
    "scorecard_array.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('performance = ', 0.69999999999999996)\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01  0.99  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x8cb1dd8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkBBFGAASoggDQEIUYQBI6P8DPFcz8+F8Yb4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x89a1588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the network backwards, given a label, see what image it produces\n",
    "\n",
    "# label to test\n",
    "label = 1\n",
    "# create the output signals for this label\n",
    "targets = numpy.zeros(output_nodes) + 0.01\n",
    "# all_values[0] is the target label for this record\n",
    "targets[label] = 0.99\n",
    "print(targets)\n",
    "\n",
    "# get image data\n",
    "image_data = n.backquery(targets)\n",
    "\n",
    "# plot image data\n",
    "matplotlib.pyplot.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
